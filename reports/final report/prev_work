Previous Work

The goal of topic modeling problem is to recover the model parameters in polynomial time, assuming
the data was generated perfectly from the hypothesized model using an unknown set of parameters. The approach presented by Arora et. al\cite{Arora12} provably recovers the model parameters based on the seperability assumptions. 

Sampling-based algorithms and variational algorithms are the two classes of topic modelling algorithms. The former includes Gibbs sampling, where we construct a sequence of random variables, each dependent on the previous one. Variational algorithms approach it from an optimization perspective by using probabilistic modelling\cite{blei}. Latent Dirichlet Allocation(LDA) falls under this category which assumes that priors that have the form of the Dirichlet distribution. 

A similar approach is used by Anandkumar et al\cite{anand}. which does not require not require separability assumptions and like LDA assumes that topics are not correlated. These models therefore fail in capturing correlations between topics. Pachinko Allocation Model(PAM) captures the concepts of topics as distribution over words as well as the correlation between topics but the topics and their relations have to be manually selected\cite{pam}.


Li, Wei, David Blei, and Andrew McCallum. "Nonparametric bayes pachinko allocation." arXiv preprint arXiv:1206.5270 (2012). 

