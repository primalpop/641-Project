\documentclass[a4paper,11pt]{article}

\usepackage[big]{layaureo} 				%better formatting of the A4 page

\usepackage{graphics}
\usepackage{graphicx}

%Setup hyperref package, and colours for links
\usepackage{hyperref}

\begin{document}

%--------------------TITLE-------------

\title{Document Similarity using topic models and anchor words}
\author{Primal Pappachan, Sunil Gandhi, Ravendar Lal \\ 
\texttt{primal1@umbc.edu, sunilga1@umbc.edu, rlal1@umbc.edu}}
\date{\today}
\maketitle

%--------------------SECTIONS----------------------------------


\section{Abstract}
Understanding topics related to a document is an important problem. It has its applications in advertising, search engines,etc. [1] paper suggest that understanding topics about a document can be formulated as problem of non negative matrix factorization. It proves that this problem is NP hard and suggests the use of anchor words to simplify the problem. It suggests NMF as replacement of LDA algorithm by making a claim that using anchor words is less stronger assumptions and this assumption holds in real life datasets. But, it doesn't give any empirical results proving these claims. We empirically evaluate these claims and check whether anchor words assumption hold on real life datasets. \\

Most document classification algorithms require us to calculate distance between two documents based on their similarity. We are using topic models to find semantic distance between two documents. We have also considered effect of anchor words on finding semantic distance and find if there is any improvement in accuracy distance. This paper evaluates empirically effect of different distance measures for finding document similarity using topic models and suggest which distance measure is best suited for this problem

\pagebreak

\section{Introduction}
A huge number of documents are generated daily in form of journals, papers from conferences and newspaper articles. A large amount of unstructured data is already present on web in form of wikipedia, web pages and social network sites. A user usually cannot read all the data available to him. Also, reading through data to find out more about document is not a very feasible option considering the number of documents available. In these cases it is important to understand the document and suggest users for relevant documents on certain topics or it would benefit if suggest the documents related to one that he is actually using. We think that topic models can be helpful in performing such tasks. \\

Topic modeling is an unsupervised approach that learns thematic structure from documents. It is a general observation that given a collection of documents, there are atleast few words that helps to differentiate one document from other even if higher level topics are same like articles of sports category. Articles of football will differ from baseball based on keywords specific to its game. \\

The other applications where we can use topic models is during searching. For example, topic models are ideal for searching on social media sites like quora. On quora there are large number of question and answer and it would be good if user could search through topics and find question and answers which are related to his topic of interest. Organizations like New York Times present another example where topic modeling can be very handy. NY Times has articles since 1851. Itâ€™ll be next to impossible to tag them as tagging was not that common before emergence of computer. Methods like topic modeling can help to mine and classify these large corpus of documents. Also, finding advertisements which are related to query that user just searched and is probably interested in is an interesting problem whose roots lie in topic models. So, topic models have their application in various fields like advertisement, searching, recommendation engine, etc. \\

[1] Suggests that problem of topic modelling can be formulated as problem of factorization of matrix into non-negative matrices. It also suggests use of anchor words to make this problem tractable. But, no empirical results of NMF and LDA which is another method of solving problem of topic models is given. Although they theoretically, suggest that NMF is better than LDA and it makes less severe assumption of separability. We are experimentally verifying this claim and check for severity of "separability" assumption on real life dataset. We are also comparing two documents based on their distribution over topic models. For this comparison, we can try different distance measures and understand which distance measure works best with topic models. This problem is significant because, understanding distance measures can be helpful in all types of machine learning problems like clustering, classification etc. It will also be useful in understanding changes in document stream over time. Understanding these changes can be important for machine learning algorithms which work on this data as stated in [2]. \\

In this paper, we have experimented and verified the approaches that are theoretically mentioned in the paper. In following section, we have mentioned some of the previous and algorithms that are used to evaluate topic models. There are many different approaches but we have mentioned some of most prominent ones. After that you will see detailed discussion about our methods that we are using along with some of the preliminary results that we might be improving upon by final report. \\

\section{Previous Work}

The goal of topic modeling problem is to recover the model parameters in polynomial time, assuming the data was generated perfectly from the hypothesized model using an unknown set of parameters. The approach presented by Arora et. al\cite{tm} provably recovers the model parameters based on the seperability assumptions. \\

Sampling-based algorithms and variational algorithms are the two classes of topic modelling algorithms. The former includes Gibbs sampling, where we construct a sequence of random variables, each dependent on the previous one. Variational algorithms approach it from an optimization perspective by using probabilistic modelling\cite{blei}. Latent Dirichlet Allocation(LDA) falls under this category which assumes that priors that have the form of the Dirichlet distribution.\\ 

A similar approach is used by Anandkumar et al\cite{anand12}. which does not require not require separability assumptions and like LDA assumes that topics are not correlated. These models therefore fail in capturing correlations between topics. Pachinko Allocation Model(PAM) captures the concepts of topics as distribution over words as well as the correlation between topics but the topics and their relations have to be manually selected\cite{pam}.



\section{Topic Modelling using NMF}
\cite{tm} introduces the topic modelling using non negative matrix factorization. This paper makes assumption that documents are distribution over words which is generated by product of two matrices which are distribution over words of topics and distribution of topics over documents.\\

The matrix which defines distribution of topics over documents is given by W and matrix which gives distribution of words over each topics is given by A. The Arora et al. \cite{tm} algorithm has two steps: anchor selection, which identifies anchor words,and recovery, which recovers the parameters of A and of R. Thus, AW = M, where M is term by document matrix. The learning problem is to find matrix A and W such that both these matrices can have only non negative values. The two problems with this approach are: \\

\begin{enumerate}
\item Term by document matrix is approximation of product of A and W.
\item Calculation of non negative matrix factors of a certain matrix is np-hard problem.
\end{enumerate}

If $\hat{M}$  is approximation of product of A and W, then $\hat{M} \hat{M}^T -> M M^T $ and $W W^T -> R$ as number of documents increases.Hence, the 	algorithm proposed by Arora solves first problem by computing word word co-occurrence matrix. \\

For calculation of matrices A and W, Arora et al. \cite{tm} makes separability assumption. It assumes existence of anchor words which are highly suggestive of topics. Since anchor words are highly suggestive of topic, the distribution of topic will have one topic with value approximately equal to one and all other values approximately equal to 0. Anchor words are the extreme points in word word co-occurrence matrix and all other words are convex combination of anchor words. So, anchor words form convex hull over all words as shown in \ref{fig:convexhull}. If we remove any word other than anchor word, convex hull does not change, but if we remove anchor word convex hull changes. Arora et al. \cite{tm} algorithm is based on this property of anchor words. \\

\begin{figure}[htb]
\includegraphics[scale=0.4]{convexhull.png}
\caption{Convex hull formed after joining anchor words \cite{tm}}
\label{fig:convexhull}
\end{figure}
The high level sketch of algorithm as proposed by \cite{tm} is given in \ref{fig:algorithm}.

\begin{figure}[htb]
\includegraphics[scale=0.5]{algorithm.png}
\caption{Algorithm for finding Anchor words }
\label{fig:algorithm}
\end{figure}


\begin{itemize} 
\item Pure model - based on the assumption that a document belongs to a single topic
\item Latent Dirichlet Allocation(LDA)
\item Corelated Topics model based on Pachinko Allocation
\end{itemize} 
These models use algorithms which requires information about the maximum likelihood of observed data, can be hard to compute. Also the spectral methods, like computing the Singular Value Decomposition(SVD) of the document corpus for learning topic models can result in unnecessary computations(positive and negatives). Instead, in this paper authors propose usage of NMF for learning topic models. They also suggest that if we assume existence of anchor words we can compute parameters of distribution of document in polynomial time. 

\section{Dataset}
Dataset: We have evaluated various datasets. Following is the list of datasets that we considered:

\begin{itemize}
\item New York Times Dataset
\item AP Press Dataset
\item NIPS Dataset
\end{itemize}

After evaluation, we chose AP Press Dataset for our experiments. New York Times dataset is hard to get hold off since it is not available for free. 


\section{Methods}
We evaluated number of approaches to find the distance similarity between two documents. We have mainly focused on the approaches mentioned in paper [1] and tried to implement what they have mentioned. This concept of anchor words, words that helps to decide the topic of a document, is very promising. Though it comes with different inherit problems like it is not easy to find anchor words for every document and sometimes having more documents make it more complex to find anchor words as it might overlap with other documents as well. Despite all this, Anchor words helps to differentiate one document from other contextually. In following methods we will see how to find anchor words along and how to use them to find the similarity among documents. \\


\subsection{Recovering Word Topic Matrix}
The algorithm we have implemented is based on a probabilistic approach where we find the conditional probabilities of words given topics using Bayes theorem. For this purpose we use the row-normalized word co-occurence matrix $\bar{Q}$ which gives the conditional probability among pairs of words. So given $\hat{Q_{i}}$, which is a row of the empirical row normalized co-occurrence matrix we wish to find out the $p(\frac{z_{1}}{w_{1}=i}$ which can best recover the rows as a convex combination of the anchor words. This step can be done in parallel using exponeniated gradient algorithm. The word topic matrix can be recovered once we have $p(\frac{z_{1}}{w_{1}}$ using Baye's rule. 

\subsection{Document Similarity Using Topic Models}
We are implementing distance matrix algorithm to find out the similarity between two documents. This distance basically tells us how similar or dissimilar two documents are. We are using our topic model algorithm in this. Basically, after getting the scores of all the topics in each of the documents, We evaluate the euclidean distance between two topics in each of these two document. And the Highest score among topics will tell which topic best describes the relationship among two documents. We have not fully implemented this yet but we are in good position to complete this very soon and add the results in final report. Figure 1 demonstrate one example where two differentdocuments in sports category are considered for topics Football, Baseball and Basketball. 



\begin{figure}[ht!]
\centering
\includegraphics[width=180mm]{document_similarity.jpg}
\caption{Document Similarity using topic model}
\label{overflow}
\end{figure}



\section{Results}
We are currently experimenting and evaluating the results and will be able to publish the results in final report. This draft procudes a good image where we stand. 

\section{Future Work}

\begin{itemize}

\item Generating Variable-Length topics modelling using sequitur algorithm:
	In existing approaches for topic modelling it only finds topics on length of single word. But this might not necessarily be the case. We would like to find topics of variable length. One approach for doing this is applying topic modelling over rules generated by algorithms like sequitur rather than applying rules over words.

\item Recommendar systems using topic modelling:
	LDA assumes that priors that have the form of the Dirichlet distribution. LDA can applied to predict review scores based on the content of reviews and to uncover implicit community structures in a social network. It can be also extended to include general meta-data of users and objects.

\end{itemize}


\begin{thebibliography}{99}
\bibitem{tm} \textit{Learning Topic Models---Going beyond SVD}. Arora, Saneev, Rong Ge, and Ankur Moitra. In FOCS 2012.
\bibitem{dred} \textit{Online methods for multi-domain learning and adaptation}. Dredze, Mark and Crammer, Koby. In
EMNLP, 2008.
\bibitem{nmf} \textit{Computing a nonnegative matrix factorization--provably}. Sanjeev Arora, Rong Ge, Ravi Kannan, Ankur Moitra. Proceedings of the 44th symposium on Theory of Computing. ACM, 2012.  
\bibitem{blei} \textit{Review article on Probabilistic topic models}. David m. Blei  

\bibitem{pam} \textit{Nonparametric bayes pachinko allocation}. Li, Wei, David Blei, and Andrew McCallum. arXiv preprint arXiv:1206.5270 (2012). 

\bibitem{anand12} \textit{Two svds suffice: Spectral decompositions for probabilistic topic modeling and latent dirichlet allocation}. Anandkumar, Animashree, et al.  arXiv preprint arXiv:1204.6703 (2012).



\end{thebibliography}





\pagebreak


\end{document}